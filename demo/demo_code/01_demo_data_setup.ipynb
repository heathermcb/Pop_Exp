{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction \n",
    "\n",
    "The purpose of this notebook, along with 02_demo_example_run.ipynb and 03_demo_explore_results.ipynb, is to provide a tutorial of how you may want to use the Pop_Exp package functions.\n",
    "\n",
    "This notebook cleans some raw data files for use in the Pop_Exp functions, and then the subsequent two notebooks run the functions and explore results. \n",
    "\n",
    "Prerequisites: This tutorial assumes that you have a version of Python installed on your computer compatible with the requirements of Pop_Exp, you have an IDE, and youâ€™re able to open and run a Jupyter notebook as well as Python scripts, and activate a virtual environment in which to run this notebook and Pop_Exp. Congrats! If you're reading this you probably opened the notebook and hopefully can run it! \n",
    "\n",
    "#### Outline\n",
    "1. What are we doing in this tutorial?\n",
    "2. Activating the pop_exp environment\n",
    "3. Data used in this tutorial\n",
    "4. What can Pop_Exp do?\n",
    "5. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What are we doing in this tutorial? \n",
    "\n",
    "This tutorial will teach you how to use Pop_Exp to find the number of people residing near California wildfire disasters, as well as the number of people residing near California wildfire disasters by ZCTA, across the years 2016-2018. We will discuss the details of how Pop_Exp allows you to define exposure to environmental hazards shortly. \n",
    "\n",
    "Pop_Exp stands for Population Exposure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activating the pop_exp environment\n",
    "\n",
    "We've provided an environment file that contains the requirments of Pop_Exp in the same GitHub folder as this tutorial. If you're running a script that loads and runs Pop_Exp functions from the command line, you can install and activate this environment before you run that script from the command line. If you want to run this tutorial or your own notebook that uses Pop_Exp, you can install this environment, make a Jupyter kernel, and run the notebook in it. \n",
    "\n",
    "Briefly, if you wanted to run a script using Pop_Exp from the command line, you could:\n",
    "\n",
    "1. Open a terminal window and navigate to this repository using cd.\n",
    "2. Create the environment by running: conda env create -f pop_exp.yml\n",
    "3. Activate this environment using: conda activate pop_exp\n",
    "4. Run your script.\n",
    "\n",
    "To create a kernel, you need to run:\n",
    "python -m ipykernel install --user --name pop_exp --display-name \"Python (pop_exp)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data used in this tutorial\n",
    "\n",
    "Functions available in Pop_Exp: Pop_Exp allow the user to estimate either (a) the number of people living within the buffer distance of each hazard (e.g., the number of people living within 10 km of each individual wildfire disaster burned area in 2018 in California) or (b) the number of people living within the buffer distance of any of the cumulative set of hazards (e.g., the number of people living within 10 km of any wildfire disaster burned area in 2018 in California). These estimates can be broken down by additional spatial units such as ZCTAs; for example, Pop_Exp can find the number of people living within 10 km of any wildfire disaster burned area in 2018 by ZCTA, and calculate spatial unit denominators such as the number of residents in each ZCTA. \n",
    "\n",
    "In this tutorial, we'll use a publicly available dataset of US wildfire disaster boundaries for the years 2016-2018 filtered to California as our hazard data, and demonstrate all the different ways Pop_Exp can be used to do detemine population exposure. \n",
    "\n",
    "To create these estimates, Pop_Exp can take up to four inputs: (1) a geospatial dataset of environmental hazards, (2) a gridded population dataset, (3) a buffer distance, and (4) an optional additional geospatial dataset of administrative geographies such as postal codes, census tracts, or counties.\n",
    "\n",
    "If you want to run this tutorial yourself, you can run the code below that creates a directory within the demo folder called demo_data, and populate the 01_raw_data folder with the three files listed below. This code also creates 02_interim_data, and 03_results, as subdirectories of the demo_data folder. This tutorial will populate those folders. Note that the raster dataset may take a few minutes to download depending on your internet, so you may want to start the download before you intend to work through the tutorial. \n",
    "\n",
    "A description of the wildfire dataset and a link for download is available here: \n",
    "\n",
    "Description:\n",
    "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/R73R85\n",
    "Download link:\n",
    "https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/R73R85#\n",
    "\n",
    "This tutorial will demonstrate how to find the number of people residing within a buffer of these wildfires by ZCTA, so we'll also use a shapefile of 2020 ZCTAs, described in detail and available for download here:\n",
    "\n",
    "Description:\n",
    "https://www.census.gov/programs-surveys/geography/guidance/geo-areas/zctas.html\n",
    "Download link:\n",
    "https://www2.census.gov/geo/tiger/TIGER2020/ZCTA520/tl_2020_us_zcta520.zip\n",
    "\n",
    "For the required gridded population data, which is used by the function to determine how many people live where, we'll use the version of the Global Human Settlement Layer which describes the residential population of the globe at 100 m resolution for 2020, and download only the tile that covers California. We used the file with Mollweide coordinate reference system, but any would work. It's downloadable here: \n",
    "\n",
    "Description:\n",
    "https://human-settlement.emergency.copernicus.eu/download.php?ds=pop\n",
    "Download:\n",
    "https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/GHSL/GHS_POP_GLOBE_R2023A/GHS_POP_E2020_GLOBE_R2023A_54009_100/V1-0/tiles/GHS_POP_E2020_GLOBE_R2023A_54009_100_V1_0_R5_C8.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What can Pop_Exp do? \n",
    "\n",
    "The Python package Pop_Exp can do five distinct computations. \n",
    "\n",
    "1. Find the total number of people who reside within a buffer distance (which can vary by hazard or be 0) of *ANY* environmental hazard in a set of hazards.\n",
    "2. Find the total number of people who reside within a buffer distance (which can vary by hazard or be 0) of *EACH* environmental hazard in a set of hazards.\n",
    "3. Find the total number of people who reside within a buffer distance (which can vary by hazard or be 0) of *ANY* environmental hazard in a set of hazards, by additional spatial unit (ex. the total number of people who resided within 10km of any wildfire disaster in 2018 by ZCTA).\n",
    "4. Find the total number of people who reside within a buffer distance (which can vary by hazard or be 0) of *EACH* environmental hazard in a set of hazards, by additional \n",
    "spatial unit. \n",
    "5. Find the number of people residing within each spatial unit according to a gridded population dataset. \n",
    "\n",
    "The fifth function is meant to provide denominators for computations (3) and (4). For example, you may want to find the total number of people who lived within 10km of any wildfire disaster in 2018 by ZCTA, and then calculate the proportion of the ZCTA population that was exposed. To do this, you could use a function in Pop_Exp to find the ZCTA population according to the gridded population raster you used to determine exposure. \n",
    "\n",
    "This tutorial will demonstrate all of these options. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demo all the functions available in Pop_Exp, we will do five separate computations, which align with the five options available in the package. \n",
    "\n",
    "1. Find the total number of people residing within 10km of *ANY* California wildfire \n",
    "disaster in 2016, 2017, and 2018. \n",
    "2. Find the total number of people residing within 10 km of *EACH* California wildfire\n",
    "disaster in 2016, 2017, and 2018.\n",
    "3. Find the total number of people residing within 10km of *ANY* California wildfire \n",
    "disaster in 2016, 2017, and 2018 by 2020 ZCTA. \n",
    "4. Find the total number of people residing within 10 km of *EACH* California wildfire\n",
    "disaster in 2016, 2017, and 2018 by 2020 ZCTA.\n",
    "5. Find the population of all 2020 California ZCTAs. \n",
    "\n",
    "To do the first two computations, we need to call the Pop_Exp function \n",
    "find_number_of_people_affected. The function parameter by_unique_hazard allows\n",
    "us to specify whether we want to find the total number of people residing near \n",
    "*any* hazard, or *each* hazard. When by_unique_hazard = False, the function \n",
    "computes the number of people exposed to any hazard. When it's True, it computes\n",
    "a total for each unique hazard. \n",
    "\n",
    "To do the second computations, we'll call the function \n",
    "find_number_of_people_affected_by_geo. As with find_number_of_people_affected, \n",
    "when by_unique_hazard = False, the function computes the number of people \n",
    "exposed to any hazard by ZCTA, and when it's True, it computes\n",
    "a total number of people affected for each unique hazard by ZCTA. \n",
    "\n",
    "We'll do these computations in the next section, and prepare data in this section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "\n",
    "This is where we start coding! First we import some libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by preparing the wildfire data. We'll set directories, and then \n",
    "read in the raw wildfire data as downloaded from Harvard dataverse. Note that\n",
    "the raw data contains wildfire disasters for years 2000-2019, which is a lot, \n",
    "and we're going to filter down to only 2016-2018 for this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = pathlib.Path.cwd().parent\n",
    "data_dir = base_path / \"demo_data\"\n",
    "\n",
    "# create subdirectories if not already existing\n",
    "subfolders = ['01_raw_data', '02_interim_data', '03_results']\n",
    "\n",
    "# make data dir and subfolders\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(data_dir, subfolder)\n",
    "    if not os.path.exists(subfolder_path):\n",
    "        os.makedirs(subfolder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in US wildfire dataset\n",
    "fires = gpd.read_file(data_dir / \"01_raw_data\"/ \"wfbz_disasters_conus.geojson\")\n",
    "# filter to only CA fires - wildfire_states has to contain CA\n",
    "fires = fires[fires['wildfire_states'].str.contains('CA')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot the data to make sure the dataset read in correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both find_num_people_affected, and find_number_of_people_affected_by_geo, \n",
    "when we run the functions, we need to pass a path to a hazard dataframe with \n",
    "3 columns:  ID_climate_hazard, buffer_dist, and geometry. So we need to decide \n",
    "on a buffer distance and create that column, and rename the other columns to \n",
    "the correct names. \n",
    "\n",
    "For this tutorial, we've decided we want to consider people exposed to a wildfire\n",
    "if they live within 10 km of the boundaries of the wildfire disasters that are\n",
    "specified in my dataset. You could do something different if you think the \n",
    "relevant distance from your hazard is different. You can also assign a buffer\n",
    "of 0 to your hazards, or different buffers to each hazard in your dataset. They\n",
    "don't all have to be the same. You could even assign buffers based on the hazard area, or another characteristic of each hazard.\n",
    "\n",
    "The buffer distance is in meters, so we'll specify a 10,000 m buffer distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires[\"buffer_dist\"] = 10000 # buffer distance in in meters \n",
    "fires.head # Checking what columns I have in the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created a buffer distance column. We need to select and rename the\n",
    "remaining columns we need, but we also need to select the years \n",
    "we're interested in. \n",
    "\n",
    "Here, we're interested in years 2016-2018, and we want to determine \n",
    "exposure by year. We want to compute the total number of people affected by any \n",
    "fire in 2016, 2017, and 2018, as well as apply the three other exposure definitions we\n",
    "wrote out above yearly.\n",
    "\n",
    "There is no option in Pop_Exp to indicate which hazards are for which year, or time period. If we want to know the total number of people affected by hazards in 2016 but not 2017, we need to feed Pop_Exp the exposure data for 2016 along with a gridded population dataset that represents the population in 2016. If I wanted monthly exposure for 2016, I'd need to split my exposure data up by month and call the function separately on each month. \n",
    "\n",
    "In this tutorial, we'll use the GHSL data from 2020 for each year 2016-2018, since it's close enough, but split up the hazard data because we want yearly counts.\n",
    "\n",
    "So before selecting just the ID, hazard, and buffer distance columns, we're going to select and split up the years we're interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select fires in 2016, 2017, 2018\n",
    "fires = fires[fires[\"wildfire_year\"].isin([2016, 2017, 2018])]\n",
    "# Split this into a list of dataframes by year\n",
    "fires_by_year = [fires[fires[\"wildfire_year\"] == year] for year in [2016, 2017, 2018]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our exposure datasets, we'll select and rename the columns we need\n",
    "for Pop_Exp functions: ID_climate_hazard, buffer_dist, and geometry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, select cols\n",
    "fires_by_year = [fire[[\"wildfire_id\", \"buffer_dist\", \"geometry\"]] for fire in fires_by_year]\n",
    "# Then rename the wildfire ID col\n",
    "fires_by_year = [fire.rename(columns={\"wildfire_id\": \"ID_climate_hazard\"}) for fire in fires_by_year]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can write these out into an interim data folder to call \n",
    "using the Pop_Exp function, since the Pop_Exp function requires you to pass \n",
    "a path name, not an object in Python. We're using GeoJSON files because these functions require either GeoJSON or Parquet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, fire in enumerate(fires_by_year):\n",
    "    fire.to_file(data_dir / \"02_interim_data\" / f\"wildfires_{2016 + i}.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've dealt with the wildfire disaster exposure data which is going to be our\n",
    "environmental hazard data. Now we also need to get the ZCTA data into the right\n",
    "format. \n",
    "\n",
    "We've chosen to use 2020 ZCTA data, since the time period 2016-2018 is closer to the 2020 census than the 2010 census. We'll read in the data, and then select and rename the columns to be what the functions find_number_of_people_affected and find_number_of_people_affected_by_geo require. \n",
    "\n",
    "We need to rename the ZCTA ID to 'ID_spatial_unit'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm reading in the raw ZCTA data. \n",
    "zctas = gpd.read_file(data_dir / \"01_raw_data\" / \"tl_2020_us_zcta520\" / \"tl_2020_us_zcta520.shp\")\n",
    "\n",
    "# Rename \n",
    "zctas.rename(columns={\"ZCTA5CE20\": \"ID_spatial_unit\"}, inplace=True)\n",
    "# select ID_spatial_unit and geometry\n",
    "zctas = zctas[[\"ID_spatial_unit\", \"geometry\"]].copy()\n",
    "zctas.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, after selecting just ZCTAs in California, we'll save this as a GeoJSON file as well. This additional spatial unit \n",
    "file can also be in GeoJSON or Parquet format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to zctas in CA\n",
    "zctas = zctas[pd.to_numeric(zctas['ID_spatial_unit']).between(90000, 96100)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take a few seconds. \n",
    "zctas_path = data_dir / \"02_interim_data\" / \"zctas_CA_2020.geojson\"\n",
    "zctas.to_file(zctas_path, driver = 'GeoJSON')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the gridded population raster doesn't require any preprocessing, our \n",
    "data is ready! Proceed to 02_demo_example_run.ipynb to continue the tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pop_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
